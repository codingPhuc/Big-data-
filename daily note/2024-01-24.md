map have many item 
Map : 
key value pairs dc tạo ra 
mapper execute the map function  the map function 
trong python hai value dc tạo ra the first is key the second is tuple 
Group by key : 



reduce : 
each pairs is pass to the reduce function one key one value 
the component execute the reduce function is the reducer 
many reducer group together to form reduce task 


example word counting 
we have a huge text document 
count the number of times each distince word appears in the file 

## how to slove the problem in map reduce 

![[map reduce.PNG]]
we will split the poem into small section 
moi doan cat la mot input element 
moi  doan do se vao tung mapper 
tao ra pair nhu (the , 1) , (crew ,1) 

group by key 
sort no theo thu tu tang dan pair co cung key se gom thanh 1 cai list (the[1,1,1,1]) 

the reducer 
reduce no bang cach cong lai the[4]

tuple khong co thay doi khi dc tao ra 
tuple trong python is immutable khong the thay doi
tuple so sanh voi gia tri dau tien 
```
map(key , value) : 
for each word w in value : 
	emit (w,1)
reduce  values là nhieu gia tri 
reudce(key, values)
```

Partitioning the input data
-  Scheduling the program’s execution across a
set of machines

 Performing the group by key step
▪ In practice this is is the bottleneck
buoc ngẻn co chai 
tat ca cac pairs từ group map phai gom vao group by key  , nen thuong xay ra loi bottle neck o day 
 Handling machine failures
neu co van de ve phan cung phan mem moi truong se xu ly cho minh 
 Managing required inter-machine communication
lien key nhieu may lai voi nhau 



Map worker failure

▪ Map tasks completed or in-progress at
worker are reset to idle and rescheduled

▪ Reduce workers are notified when map task is
rescheduled on another worker
 Reduce worker failure
▪ Only in-progress tasks are reset to idle and the
reduce task is restarted
khi xay ra loi o map worker thi co map task se chua hoan thanh , neu no chua hoan thanh thanh thi xe tro ve trang thai ban dau 
worker chay task trong 
neu map worker fail thi reduce worker chay 

neu reduce worker fail thi chi co task chua hoan thanh dc chay lai 






## what to learn 
ve hoc lambda cua python 







**

Course: MMDS

Tutorial 02

HDFS

# Basic Operation

## Starting HDFS

1. Format the configured HDFS filesystem (run once in the installation step)
    
bin/hdfs namenode -format

2. Start namenode, datanode, secondary namenode daemons
    

sbin/start-dfs.sh

  

## Listing Files in HDFS

de chay 3 cai lenh nay can daemon  
namenode 
secondary namenode 

yarn daemon : 
resource manager 
node manager 

1. Find the list of files in a directory, status of file
    

  

bin/hdfs dfs -ls <path/directory>

![](https://lh7-us.googleusercontent.com/9c_-QdHzCzQxI89QPw_HqhblFL5rQ3d1lfyFEk2JKV_GYMEN5Wjr7CuSGBskmlozValiZ8xzarouA5M6jrLCcHhs-P8HcnJmp0eupg6q3sHA0mtWIcy1dwnZTjMRHi71zbdhYRpMX9oX70Aw5cWGNdA)
khi khong go duong dan tuyet doi thi no se tao o cai mac dinh user trong truong hop nay la user ntan 


2. Note: root directory is /
    

  

bin/hdfs dfs -ls /

![](https://lh7-us.googleusercontent.com/QdT9nW9d_Ufx14kpUvTD3XhzJJDyhpS3LBiebmXC1EkdLhar8Oa4vHk3vsjOAdKniML6fcNcSQyPLHo9ibXW8DRra33dqb5S8aewW1psgYPuJdlmIWyhCkwAQa_KL-3yvM2zYc5WfsHYdaE4Z0UzKBI)

thu muc goc cua file system se la / 
trong thu muc goc thuong se co folder tmp and user 
3. Recursively displays entries in all subdirectories of path
    

-R duoc dung de liet ke thu muc temp , temp hadoop yarn theo dps deep first search 
  

bin/hdfs dfs -ls -R <path/directory>

![](https://lh7-us.googleusercontent.com/BAYPUq9XI4dluVwlN2AzOspoBZKpN6z0gOPdR90l7SENdyYbt49n8yhTucOQ241HXRZp4VozWsNryZcBFLEbCyMMcFaLF9bY3bJVzEXfhzlpTWM5VdBIg_aEWhqjXP4YXtUF-6iuwbt86CeU9pm5yXo)

## Inserting Data into HDFS

1. Create a directory
    

bin/hdfs dfs -mkdir <path>

![](https://lh7-us.googleusercontent.com/DqpSDBCJRiV49maal3H9RgrO9NJ33AqQgtaL_hN4rwGro94i4w3_-39TH9mgHgaJQjvEloHC2qIAFatvVllFEV1gTeKpeEFxvqhe9btNcsFxry14IbZsCjrRf6ikr__k6dcwPpX2tCkXjYmDvWXXIdE)

  

2. Transfer and store data file from local systems to HDFS
    

  
-put de tai len 
<local file/folder> duong dan den thu muc tren local 
<HDFS directory> duong dan den hdfs 
bin/hdfs dfs -put <local file/folder> <HDFS directory>

![](https://lh7-us.googleusercontent.com/vAIjOYHlZY-oGqnytwXnNblpTbFneXTSPOAJvN1A4tnY1rvFw5A16l-UBBIUuRnySBgjHClNKbAMyjunQm_dRirsS1AEQrr1DkxFLTW6Vq21DTPu0OqhjlBAuRb3wAXSJjmZ4ppIshMK-V60-asYLTw)

  

3. Verify the file
    

  

bin/hdfs dfs -ls /user/input

![](https://lh7-us.googleusercontent.com/YtwGRvDTUMbzuiL3Xqh_Wx1H1rGQ_K_C1hiZwOvvutiLMmfirsdcWd3y9kZLkqvazXjYuaA5SfFeaby-GCQ-T_KT-qxG_worREkoRCfhVx5QCqvlfH-B4H1YriH4vkx3gRsFifSXpnyeCwlCaxkyuzc)

## Retrieving Data from HDFS

1. View the data from HDFS using cat
    

  
-cat hien thi noi dung cua tap tin ra terminal 
bin/hdfs dfs -cat /user/input/test.txt

![](https://lh7-us.googleusercontent.com/0d1hYkV9980RD3kEXVcCugCDIR25RaB4NmaxqRklkM26JRWPbYnT-Z50Px3b6BHGx_yhrDOVuoHrYIgTMsRaGp4ceR2EM-N479C02mquexGX9TJROuPHpKan7575dF4ANYvBZUHSeL8sLhvtBMEA5b8)

  

2. Get the file from HDFS
    

  

bin/hdfs dfs -get /user/input/test.txt output

![](https://lh7-us.googleusercontent.com/o_S7JgXD5TJ4J1YtjPQ9cKQl64nudfJTSOE66Vl2nWHA69JCoCOkDikg_0qF5088oHFr_-9ApmuTOueYQXKQNjrwo7H_bI_-W05pkBmUILEDI90t4r2M0q9WvjHVOQl_9FWgTqV9UklcUync5e0DKEQ)

  

3. Shut down the HDFS
    

  
mo may ao mo yarn , tat yarn tat may ao tat hdfs 
sbin/stop-dfs.sh

![](https://lh7-us.googleusercontent.com/QW_7-PBBqlzOD0x5S8AB6mWSYwGbYsDB0lVSOpcUo2Xmd4anqiX9wsB8k-i2a8WGi4U_v8uB9Ap3A8kEzc6SzJqXVRN5V_70Y0bKZw6proppor9-kkgW_XfVFIuyss7V74zj6rFzadGtnLSrkNO9gSY)

# HDFS Command Syntax

![](https://lh7-us.googleusercontent.com/dm7e3On5gHk2KQ5TNM0ZjTxYRr9-_SCPvN-H9IJoZ7OFF907JBbXIaeIsigy-OpvpMXKBMNTHremwtRnjbTvB0nPnaIYB13wF97RwybqGQkIjwZ-ViVqDMHUYfgheHeYYwWuwuv2LZM0_Bj7OzHJDeo)

![](https://lh7-us.googleusercontent.com/A0vjPyqHtcZjNabOb8urTSWEN0mhRVnE8CP8NtIE41IYULTpw0eVt4zgDaSvaWPsjsMVMf3W0HCob5MSMHfyAiCCUAp6GK7PBszRXo6yTOa4ttdCAMhSH3f-xIiaPBxl3rUtMYlM44jVPLONE-JI53E)

#   
Notice for examinations

The commands below commonly appear in your examination questions.

- jps
    
- copyFrom/ToLocal
    
- get
    
- put
    
- mv
    
- mkdir
    

# References

- [https://www.tutorialspoint.com/hadoop/hadoop_hdfs_operations.htm](https://www.tutorialspoint.com/hadoop/hadoop_hdfs_operations.htm)
    
- [https://images.linoxide.com/hadoop-hdfs-commands-cheatsheet.pdf](https://images.linoxide.com/hadoop-hdfs-commands-cheatsheet.pdf)
    

  
  
  
**