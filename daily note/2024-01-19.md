To understand the concepts of **Parallel and Distributed processing by Map-reduce**, **Architecture and components of Map-reduce model**, **Operations of Map-reduce**, and **Word Counting example**, you will need to learn the following materials:

- **Introduction to Hadoop**: This will give you an overview of Hadoop, which is a framework that supports distributed processing of large data sets across clusters of computers. You can learn about the Hadoop Distributed File System (HDFS) and MapReduce programming model, which are the two major components of Hadoop. You can find a free course on edX that covers these topics.
    
- **MapReduce Architecture**: This will help you understand the architecture of MapReduce, which is a programming model used for efficient processing in parallel over large data-sets in a distributed manner. You can learn about the components of MapReduce architecture, such as the client, job, job-parts, input data, output data, and Hadoop MapReduce Master. You can find a detailed article on  that covers these topics.
    
- **MapReduce Programming**: This will help you understand how to write MapReduce programs. You can learn about the Map and Reduce phases of MapReduce programming, which are the two main phases of MapReduce task. You can find a detailed article on TutorialsPoint that covers these topics.
    
- **Hadoop Word Count Example**: This will help you understand how to write a simple MapReduce program to count the number of occurrences of each word in a text file. You can find a detailed article on Apache Hadoop that covers these topics.
    

Here is a one-week schedule that you can follow to learn these materials:

- **Day 1**: Introduction to Hadoop
- **Day 2**: MapReduce Architecture
- **Day 3**: MapReduce Programming
- **Day 4**: Hadoop Word Count Example
- **Day 5**: Practice writing MapReduce programs
- **Day 6**: Practice writing MapReduce programs
- **Day 7**: Review and practice
