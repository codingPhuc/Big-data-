
today course is related  to High Dimensional data  

vector in big data need to be high dimenstional   


given  a query image patch find similar images 


data tranformation is the act of tranformming data from one form to another usully in vector form , 
different type of vector 
vector feature 
vector embeading  

incomputerscience we like to tranfer the data from any type to numeric

math formula : Euclidean Distince 
math formula  : Manhattan  
math formula : cosin distince  



# lecture 


Given: High dimensional data points 𝒙𝟏,𝒙𝟐, …  
▪ For example: Image is a long vector of pixel colors  
 And some distance function 𝒅(𝒙𝟏, 𝒙𝟐)  
▪ which quantifies the “distance” between 𝒙𝟏 and 𝒙𝟐  
 Goal: Given 𝒒, find data points 𝒙𝒋 that are  
within distance threshold 𝒅 𝒒, 𝒙𝒋 ≤ 𝒔  
 Note: Naïve solution would take 𝑶 𝑵  
where 𝑵 is the number of data points  
 MAGIC: This can be done in 𝑶 𝟏 !! How??

given n  number number how can we find  pair that abs them s 
the algorihtm bellow help : 
	when we want 0(1) complexity we should think of hash family 
what is shingling (real world definition is the roof of house )
- convert document in too bolean vector 
- what is tokenization ?  
D1=  abcdef  -> C1  =  {ab,bc , cd , de}
D2 =  accde  ->  C2 =  {ac,cc,cd,de} 
document that are like each other 
when we change 1 word there will be k  shingling chaging (bao toan cau truc bang dau cua document ) we recoment  k of 8,9,10 
we create a new way to measure the distince jaccard distince 

Min Hashing 
converting bolean vector into signatures vectors , convert  bit vector into a unique vector embeading freture 

used a hash function to convert a  bolean vector into a signiture (unique vector) . if a1 and a2 is alike then thier signiture vector should be alike 
Min-Hashing  
Permute the rows of the boolean matrix using some permutation pi  
pi nhan vao mot vector nhi phan  xap sep phan tu theo 1 thu tu nhat dinh 
(pi is not the pi in mathetmatic  but a function that will rearange our vector )
pi() : reverse  


minhash receive a verctor then return the first value containning a  number diffferent from 0 


![[20240306_164147.jpg]]
- h pi(C1)  = 3
-  h pi(C2)  = 1

su dung nhieu hoan vi , tim ra gia tri minhash cua tung cai gep lai thanh mot vector signiture 

![[mapping.PNG]]
- here the permutaiton pi is three different vector each have different color 
- the brown column will then map with the first column of the input matrix 
- causing it to output a vector output being `[0,1,1,1,1,0,0]` this vector is create by placing the value of first column matrix to the position bases on the brown permutation matrix  the value are map from top to bottem 



`[0,1,1,1,1,0,0]`


do tuong dong cua hai vector signiture la ty le so cap phan tu khop nhau giua chung 

![[first column.PNG]]
- here the first column s1[2,2,1] have two element similar to s2[2,4,1] so they have 0.75 percentage similarity 


Locality sensittive hasihing 
time ra cac cap signiture giong nhau 





# partitiion m into band 
chia cac vector signiture  thanh cac doan 
- hash moi band 
- bo vector signiture vao bucket tuong ung 
- two vector signiture is call a canadite if they have at least have a third vector put in a bucket 

![[signature matrix.PNG]]



Suppose 100,000 columns of M (100k docs)  
 Signatures of length 100, stored as integers  
(rows)  
 Therefore, signatures take 40MB  
 Goal: Find pairs of documents that  
are at least s = 0.8 similar  
 Choose b = 20 bands of r = 5 integers/band




- The course is related to High Dimensional data.
- Vectors in big data need to be high dimensional.
- Given a query image patch, the goal is to find similar images.
- Data transformation is the act of transforming data from one form to another, usually in vector form. This includes vector features and vector embeddings.
- In computer science, we prefer to transfer the data from any type to numeric.
- There are different distance measures such as Euclidean Distance, Manhattan Distance, and Cosine Distance.



1. **High Dimensional Data Points**: These are data points that exist in a space with a high number of dimensions. For example, an image can be represented as a long vector of pixel colors.
    
2. **Distance Function 𝒅(𝒙𝟏, 𝒙𝟐)**: This is a function that quantifies the “distance” or difference between two data points 𝒙𝟏 and 𝒙𝟐.
    
3. **Goal**: Given a query point 𝒒, the goal is to find data points 𝒙𝒋 that are within a distance threshold 𝒔, i.e., 𝒅(𝒒, 𝒙𝒋) ≤ 𝒔. The naive solution would take 𝑶(𝑵) time complexity, where 𝑵 is the number of data points. However, with a suitable data structure or algorithm, this can be improved to 𝑶(1) time complexity.
    
4. **Shingling**: This is a process of converting a document into a boolean vector. It involves creating ‘shingles’ or tokens from the document. For example, given a document D1 = “abcdef”, we can create shingles C1 = {ab, bc, cd, de}. This helps in comparing documents and maintaining the structure of the document even when a word changes.
    
5. **Jaccard Distance**: This is a measure of dissimilarity between two sets. It’s defined as the size of the intersection divided by the size of the union of the two sets.
    
6. **Min Hashing**: This is a technique for converting a boolean vector into a signature vector. It uses a hash function to convert a boolean vector into a signature (unique vector). If two vectors are similar, their signature vectors should also be similar. The process involves permuting the rows of the boolean matrix using some permutation function 𝜋 (not to be confused with the mathematical constant 𝜋). The minhash of a vector is the first value containing a number different from 0 after applying the permutation function.



![[mapping.PNG]]
- use multiple permutations to find the minhash value of each item, then concatenate them to form a signature vector.
- Here, the permutation 𝜋 is represented by three different vectors, each with a different color.
- The brown column will then map to the first column of the input matrix.
- This results in an output vector `[0,1,1,1,1,0,0]`. This vector is created by placing the values of the first column of the matrix into positions based on the brown permutation vector. The values are mapped from top to bottom.


The similarity between two signature vectors is determined by the proportion of matching element pairs between them.

For example, consider two signature vectors `s1 = [2,2,1]` and `s2 = [2,4,1]`. Here, the first and third elements of `s1` match with the first and third elements of `s2`. So, out of 3 total elements, 2 elements match. Therefore, the similarity between `s1` and `s2` is `2/3 = 0.67` or 67%.
![[first column.PNG]]
**Locality-Sensitive Hashing (LSH)** is a method used in data mining and machine learning to identify items that are similar. It hashes input items in such a way that similar items map to the same “buckets” with high probability. This makes it possible to identify candidate pairs of similar items without having to compare every pair of items in the dataset, which can be computationally expensive. In the context of signature vectors, LSH can be used to quickly find pairs of signatures that are similar.




partitiion m into band 
![[signature matrix.PNG]]

1. **Partition Signature Vectors into Bands**: The signature vectors are divided into segments or “bands”. Each band contains a portion of the signature vector.
    
2. **Hash Each Band**: Each band is hashed separately. This means that a hash function is applied to the elements in each band.
    
3. **Bucket Signature Vectors**: The hashed bands are then placed into “buckets”. Each bucket corresponds to a range of hash values. Signature vectors that hash to the same value for a particular band are placed in the same bucket.
    
4. **Candidate Pairs**: Two signature vectors are considered a “candidate pair” if they hash to the same bucket for at least one band. This means that they are likely to be similar. 